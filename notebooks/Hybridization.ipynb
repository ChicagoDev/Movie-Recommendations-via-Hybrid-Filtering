{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Imports\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.prediction_algorithms.knns import KNNWithZScore, KNNBaseline\n",
    "from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "from pandas.io.json import json_normalize\n",
    "from pymongo import MongoClient\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ids(ids_in_csv):\n",
    "    return pd.to_numeric(ids_in_csv, errors='coerce').astype('int64')\n",
    "\n",
    "def convert_to_float(ids_in_csv):\n",
    "    return pd.to_numeric(ids_in_csv, errors='coerce').astype('float64')\n",
    "\n",
    "def to_json(csv_entry):\n",
    "    return json.loads(re.sub('\\'', '\"', csv_entry))\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''COPIED FROM SUPRISE API\n",
    "    Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_movie_name(movie_id):\n",
    "    return ratings_with_movie_names[ratings_with_movie_names.id == movie_id]['original_title'].iloc[0]\n",
    "\n",
    "\n",
    "def print_user_prediction(userId, predictions_dict):\n",
    "    users_viewed_movies = ratings_with_movie_names[ratings_with_movie_names['userId'] == userId][\n",
    "        ['rating', 'original_title']]\n",
    "    print(f'User {userId} has viewed the following movies:\\n')\n",
    "\n",
    "    for row in users_viewed_movies.itertuples():\n",
    "        rating = row[1]\n",
    "        original_title = row[2]\n",
    "        print(f'\\t{original_title}, Rating: {rating}')\n",
    "\n",
    "    print(f'\\nThe following movies are recommended for User {userId}\\n')\n",
    "    recommended_movies = [get_movie_name(mov_id[0]) for mov_id in predictions_dict[userId]]\n",
    "\n",
    "    for movie in recommended_movies:\n",
    "        print(f'\\t{movie}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata_df = pd.read_csv('../data/the-movies-dataset/movies_metadata.csv'\n",
    "                                 , converters={ 'id': lambda x: convert_ids(x)\n",
    "                                               , 'imdb_id': lambda x: convert_ids(x)\n",
    "                                               ,'popularity': lambda x: convert_to_float(x)\n",
    "                                               ,'genres': lambda x: to_json(x)}\n",
    "                                 , usecols=['id', 'original_title'\n",
    "                                                , 'genres', 'homepage'\n",
    "                                                , 'overview', 'popularity', 'poster_path'\n",
    "                                                , 'release_date', 'revenue', 'runtime'\n",
    "                                                , 'spoken_languages', 'tagline', 'title'\n",
    "                                                , 'vote_average', 'vote_count']\n",
    "                                , dtype={'populariy': np.float64}\n",
    "                                , parse_dates=True)\n",
    "\n",
    "movies_df = pd.read_csv('data/the-movies-dataset/movies_metadata.csv'\n",
    "                        , converters={'id': lambda x: convert_ids(x), 'imdb_id': lambda x: convert_ids(x)}\n",
    "                       ,usecols=['id', 'original_title', 'belongs_to_collection'\n",
    "                                 , 'budget', 'genres', 'homepage'\n",
    "                                 ,'imdb_id', 'overview', 'popularity', 'poster_path'\n",
    "                                 , 'production_companies','release_date', 'revenue', 'runtime',\n",
    "                                 'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
    "                                 'vote_average', 'vote_count'])\n",
    "\n",
    "ratings_df = pd.read_csv('../data/the-movies-dataset/ratings_small.csv')\n",
    "\n",
    "\n",
    "\n",
    "content_filter_df = pd.read_pickle('../data/content_filter_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###May need Fuzzy matching, but for now:\n",
    "movies_df = movies_df[movies_df.spoken_languages == \"\"\"[{'iso_639_1': 'en', 'name': 'English'}]\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_with_movie_names = ratings_df.merge(movies_df[['id', 'original_title']], how='left', left_on='movieId', right_on='id')\n",
    "ratings_with_movie_names = ratings_with_movie_names[ratings_with_movie_names.original_title.isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(ratings_with_movie_names[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can try different Algorithms here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(verbose=True)\n",
    "algo.fit(trainset)\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)\n",
    "### Tune this value to get fewer results faster, but less options to choose from\n",
    "top_n = get_top_n(predictions, 200)\n",
    "\n",
    "\n",
    "predicted_movies_by_name = defaultdict(list)\n",
    "\n",
    "### This builds the dictionary of predicted movies for all users\n",
    "for key, value in top_n.items():\n",
    "    predicted_movies_by_name[key] = [get_movie_name(mov_id[0]) for mov_id in value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, you should have user personas to get a pool of movies to choose from, not simply pre-made users:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "    print_user_prediction(321, top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Fitting\n",
    "#Surprise SVD Collaborative Filtering\n",
    "#Topic Modeling Based on Movie Descriptions\n",
    "#ContentFiltering ... Not finished...? Or was it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Merging\n",
    "#Genre Constrictions\n",
    "#Neo4j Graph Degree Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 OSX",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
